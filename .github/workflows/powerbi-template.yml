# .github/workflows/deploy-powerbi.yml
# Reusable workflow for Power BI file deployment using Fabric APIs
# Updated to support definition files inside definition/ subfolder
name: Deploy Power BI Files to Workspace

on:
  workflow_call:
    inputs:
      environment:
        description: 'Target environment (dev/uat/prod)'
        required: true
        type: string
      branch:
        description: 'Git branch to deploy from'
        required: true
        type: string
      workspace_id:
        description: 'Target workspace ID'
        required: true
        type: string
      reports_path:
        description: 'Path to search for .Report and .SemanticModel folders (relative to repo root)'
        required: false
        type: string
        default: '.'
    secrets:
      AZURE_CLIENT_ID:
        required: true
      AZURE_CLIENT_SECRET:
        required: true
      AZURE_TENANT_ID:
        required: true
    outputs:
      deployment_status:
        description: 'Status of the deployment'
        value: ${{ jobs.deploy.outputs.status }}
      deployed_reports:
        description: 'List of deployed reports'
        value: ${{ jobs.deploy.outputs.deployed_reports }}
      deployed_datasets:
        description: 'List of deployed semantic models'
        value: ${{ jobs.deploy.outputs.deployed_datasets }}

env:
  FABRIC_API_BASE_URL: 'https://api.fabric.microsoft.com/v1'

jobs:
  deploy:
    name: Deploy to ${{ inputs.environment }} Workspace
    runs-on: ubuntu-latest
    outputs:
      status: ${{ steps.deployment.outputs.status }}
      deployed_reports: ${{ steps.deployment.outputs.deployed_reports }}
      deployed_datasets: ${{ steps.deployment.outputs.deployed_datasets }}
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.branch }}
      
      - name: Get Access Token for Fabric API
        id: get-token
        run: |
          echo "Getting access token for Fabric API..."
          
          # Get OAuth token using client credentials flow
          TOKEN_RESPONSE=$(curl -s -X POST \
            "https://login.microsoftonline.com/${{ secrets.AZURE_TENANT_ID }}/oauth2/v2.0/token" \
            -H "Content-Type: application/x-www-form-urlencoded" \
            -d "client_id=${{ secrets.AZURE_CLIENT_ID }}" \
            -d "client_secret=${{ secrets.AZURE_CLIENT_SECRET }}" \
            -d "scope=https://api.fabric.microsoft.com/.default" \
            -d "grant_type=client_credentials")
          
          # Extract access token
          ACCESS_TOKEN=$(echo "$TOKEN_RESPONSE" | jq -r '.access_token // empty')
          
          if [ -z "$ACCESS_TOKEN" ] || [ "$ACCESS_TOKEN" = "null" ]; then
            echo "‚ùå Failed to get access token"
            echo "Response: $TOKEN_RESPONSE"
            exit 1
          fi
          
          echo "‚úÖ Successfully obtained access token"
          echo "::add-mask::$ACCESS_TOKEN"
          echo "FABRIC_TOKEN=$ACCESS_TOKEN" >> $GITHUB_ENV
      
      - name: Validate Workspace Connection
        id: validate
        run: |
          echo "Validating workspace connection..."
          WORKSPACE_ID="${{ inputs.workspace_id }}"
          
          # Get workspace details
          WORKSPACE_RESPONSE=$(curl -s -w "\nHTTP_STATUS:%{http_code}" -X GET \
            "${{ env.FABRIC_API_BASE_URL }}/workspaces/$WORKSPACE_ID" \
            -H "Authorization: Bearer ${{ env.FABRIC_TOKEN }}")
          
          HTTP_STATUS=$(echo "$WORKSPACE_RESPONSE" | grep HTTP_STATUS | cut -d: -f2)
          BODY=$(echo "$WORKSPACE_RESPONSE" | sed '/HTTP_STATUS/d')
          
          if [ "$HTTP_STATUS" -ne 200 ]; then
            echo "‚ùå Failed to access workspace"
            echo "Status: $HTTP_STATUS"
            echo "Response: $BODY"
            exit 1
          fi
          
          WORKSPACE_NAME=$(echo "$BODY" | jq -r '.displayName')
          echo "‚úÖ Workspace validated: $WORKSPACE_NAME"
          echo "workspace_name=$WORKSPACE_NAME" >> $GITHUB_OUTPUT
      
      - name: Find Power BI Items
        id: find-files
        run: |
          echo "=========================================="
          echo "SEARCHING FOR POWER BI ITEMS"
          echo "=========================================="
          echo "Search path: ${{ inputs.reports_path }}"
          echo ""
          
          if [ ! -d "${{ inputs.reports_path }}" ]; then
            echo "‚ùå Error: Search path '${{ inputs.reports_path }}' does not exist"
            exit 1
          fi
          
          # Find all .Report folders
          echo "=== Searching for Reports ==="
          REPORT_FOLDERS=$(find "${{ inputs.reports_path }}" -type d -name "*.Report" | sort)
          REPORT_COUNT=$(echo "$REPORT_FOLDERS" | grep -c . || echo "0")
          
          echo "Found $REPORT_COUNT .Report folder(s)"
          
          VALID_REPORTS=0
          > /tmp/reports_to_deploy.txt
          
          if [ "$REPORT_COUNT" -gt 0 ]; then
            while IFS= read -r FOLDER; do
              [ -z "$FOLDER" ] && continue
              
              # Check for definition.pbir in multiple possible locations
              PBIR_FILE=""
              if [ -f "$FOLDER/definition.pbir" ]; then
                PBIR_FILE="$FOLDER/definition.pbir"
              elif [ -f "$FOLDER/definition/definition.pbir" ]; then
                PBIR_FILE="$FOLDER/definition/definition.pbir"
              fi
              
              if [ -n "$PBIR_FILE" ]; then
                echo "  ‚úì $FOLDER"
                echo "    Definition file: $PBIR_FILE"
                echo "$FOLDER" >> /tmp/reports_to_deploy.txt
                VALID_REPORTS=$((VALID_REPORTS + 1))
              else
                echo "  ‚úó $FOLDER (missing definition.pbir)"
              fi
            done <<< "$REPORT_FOLDERS"
          fi
          
          # Find all .SemanticModel folders
          echo ""
          echo "=== Searching for Semantic Models ==="
          DATASET_FOLDERS=$(find "${{ inputs.reports_path }}" -type d -name "*.SemanticModel" | sort)
          DATASET_COUNT=$(echo "$DATASET_FOLDERS" | grep -c . || echo "0")
          
          echo "Found $DATASET_COUNT .SemanticModel folder(s)"
          
          VALID_DATASETS=0
          > /tmp/datasets_to_deploy.txt
          
          if [ "$DATASET_COUNT" -gt 0 ]; then
            while IFS= read -r FOLDER; do
              [ -z "$FOLDER" ] && continue
              
              # Check for definition.pbism in multiple possible locations
              PBISM_FILE=""
              if [ -f "$FOLDER/definition.pbism" ]; then
                PBISM_FILE="$FOLDER/definition.pbism"
              elif [ -f "$FOLDER/definition/definition.pbism" ]; then
                PBISM_FILE="$FOLDER/definition/definition.pbism"
              fi
              
              if [ -n "$PBISM_FILE" ]; then
                echo "  ‚úì $FOLDER"
                echo "    Definition file: $PBISM_FILE"
                echo "$FOLDER" >> /tmp/datasets_to_deploy.txt
                VALID_DATASETS=$((VALID_DATASETS + 1))
              else
                echo "  ‚úó $FOLDER (missing definition.pbism)"
              fi
            done <<< "$DATASET_FOLDERS"
          fi
          
          echo ""
          echo "=== Summary ==="
          echo "Valid reports to deploy: $VALID_REPORTS"
          echo "Valid semantic models to deploy: $VALID_DATASETS"
          
          TOTAL_ITEMS=$((VALID_REPORTS + VALID_DATASETS))
          
          if [ "$TOTAL_ITEMS" -eq 0 ]; then
            echo "‚ùå No valid Power BI items found"
            exit 1
          fi
          
          echo "report_count=$VALID_REPORTS" >> $GITHUB_OUTPUT
          echo "dataset_count=$VALID_DATASETS" >> $GITHUB_OUTPUT
          echo "total_count=$TOTAL_ITEMS" >> $GITHUB_OUTPUT
      
      - name: Deploy Semantic Models to Workspace
        id: deploy-datasets
        run: |
          echo ""
          echo "=========================================="
          echo "DEPLOYING SEMANTIC MODELS"
          echo "=========================================="
          
          WORKSPACE_ID="${{ inputs.workspace_id }}"
          DEPLOYED_DATASETS=""
          SUCCESS_COUNT=0
          FAILED_COUNT=0
          
          if [ ! -f /tmp/datasets_to_deploy.txt ] || [ ! -s /tmp/datasets_to_deploy.txt ]; then
            echo "‚ÑπÔ∏è  No semantic models to deploy"
            echo "deployed_datasets=" >> $GITHUB_OUTPUT
            echo "dataset_success=0" >> $GITHUB_OUTPUT
            echo "dataset_failed=0" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Deploy each semantic model
          while IFS= read -r DATASET_FOLDER; do
            [ -z "$DATASET_FOLDER" ] && continue
            
            DATASET_NAME=$(basename "$DATASET_FOLDER" .SemanticModel)
            
            echo ""
            echo "================================================"
            echo "üìä Deploying Semantic Model: $DATASET_NAME"
            echo "   Folder: $DATASET_FOLDER"
            echo "================================================"
            
            # Determine the definition folder location
            DEFINITION_FOLDER=""
            if [ -d "$DATASET_FOLDER/definition" ] && [ "$(find "$DATASET_FOLDER/definition" -type f | wc -l)" -gt 0 ]; then
              DEFINITION_FOLDER="$DATASET_FOLDER/definition"
            else
              echo "‚ö†Ô∏è  Warning: No definition folder found or it's empty"
              echo "   Looking for files in root folder instead"
              DEFINITION_FOLDER="$DATASET_FOLDER"
            fi
            
            echo "   Using definition folder: $DEFINITION_FOLDER"
            
            # Build definition payload from all files in definition folder
            PAYLOAD_PARTS="["
            FIRST_FILE=true
            FILE_COUNT=0
            
            # Process all files in the definition folder (excluding .platform and other metadata)
            while IFS= read -r FILE; do
              [ -z "$FILE" ] && continue
              
              # Skip .platform and other non-definition files
              BASENAME=$(basename "$FILE")
              if [[ "$BASENAME" == ".platform" ]] || [[ "$BASENAME" == ".pbi"* ]]; then
                continue
              fi
              
              # Calculate relative path - MUST include 'definition/' prefix for Fabric API
              if [ "$DEFINITION_FOLDER" = "$DATASET_FOLDER/definition" ]; then
                # Files are in definition subfolder, prepend 'definition/' to path
                RELATIVE_PATH="definition/${FILE#$DATASET_FOLDER/definition/}"
              else
                # Files are in root folder, use as-is
                RELATIVE_PATH="${FILE#$DATASET_FOLDER/}"
              fi
              
              # Read and encode file content
              FILE_CONTENT=$(base64 -w 0 < "$FILE")
              
              if [ "$FIRST_FILE" = false ]; then
                PAYLOAD_PARTS="$PAYLOAD_PARTS,"
              fi
              FIRST_FILE=false
              
              PAYLOAD_PARTS="$PAYLOAD_PARTS{\"path\":\"$RELATIVE_PATH\",\"payload\":\"$FILE_CONTENT\",\"payloadType\":\"InlineBase64\"}"
              FILE_COUNT=$((FILE_COUNT + 1))
              
              echo "   üìÑ Added file: $RELATIVE_PATH"
              
            done < <(find "$DEFINITION_FOLDER" -type f | sort)
            
            PAYLOAD_PARTS="$PAYLOAD_PARTS]"
            
            echo "   Total files to upload: $FILE_COUNT"
            echo ""
            echo "   üöÄ Creating semantic model in workspace..."
            
            # Create semantic model in workspace
            RESPONSE=$(curl -s -w "\nHTTP_STATUS:%{http_code}" -X POST \
              "${{ env.FABRIC_API_BASE_URL }}/workspaces/C5FAF867-77B6-499A-A8CD-C00C3C046218/semanticModels" \
              -H "Authorization: Bearer ${{ env.FABRIC_TOKEN }}" \
              -H "Content-Type: application/json" \
              -d "{\"displayName\":\"$DATASET_NAME\",\"definition\":{\"parts\":$PAYLOAD_PARTS}}")
            
            HTTP_STATUS=$(echo "$RESPONSE" | grep HTTP_STATUS | cut -d: -f2)
            BODY=$(echo "$RESPONSE" | sed '/HTTP_STATUS/d')
            
            if [ "$HTTP_STATUS" -eq 200 ] || [ "$HTTP_STATUS" -eq 201 ] || [ "$HTTP_STATUS" -eq 202 ]; then
              DATASET_ID=$(echo "$BODY" | jq -r '.id // "unknown"')
              echo "   ‚úÖ Successfully deployed: $DATASET_NAME"
              echo "   üìã Semantic Model ID: $DATASET_ID"
              SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
              DEPLOYED_DATASETS="$DEPLOYED_DATASETS$DATASET_NAME, "
            else
              echo "   ‚ùå Failed to deploy: $DATASET_NAME"
              echo "   üìä Status: $HTTP_STATUS"
              echo "   üìù Response: $BODY"
              FAILED_COUNT=$((FAILED_COUNT + 1))
            fi
            
          done < /tmp/datasets_to_deploy.txt
          
          DEPLOYED_DATASETS=${DEPLOYED_DATASETS%, }
          
          echo ""
          echo "=========================================="
          echo "SEMANTIC MODELS DEPLOYMENT SUMMARY"
          echo "=========================================="
          echo "Total found: ${{ steps.find-files.outputs.dataset_count }}"
          echo "‚úÖ Success: $SUCCESS_COUNT"
          echo "‚ùå Failed: $FAILED_COUNT"
          echo "=========================================="
          
          echo "deployed_datasets=$DEPLOYED_DATASETS" >> $GITHUB_OUTPUT
          echo "dataset_success=$SUCCESS_COUNT" >> $GITHUB_OUTPUT
          echo "dataset_failed=$FAILED_COUNT" >> $GITHUB_OUTPUT
      
      - name: Deploy Reports to Workspace
        id: deploy-reports
        run: |
          echo ""
          echo "=========================================="
          echo "DEPLOYING REPORTS"
          echo "=========================================="
          
          WORKSPACE_ID="${{ inputs.workspace_id }}"
          DEPLOYED_REPORTS=""
          SUCCESS_COUNT=0
          FAILED_COUNT=0
          
          if [ ! -f /tmp/reports_to_deploy.txt ] || [ ! -s /tmp/reports_to_deploy.txt ]; then
            echo "‚ÑπÔ∏è  No reports to deploy"
            echo "deployed_reports=" >> $GITHUB_OUTPUT
            echo "report_success=0" >> $GITHUB_OUTPUT
            echo "report_failed=0" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Deploy each report
          while IFS= read -r REPORT_FOLDER; do
            [ -z "$REPORT_FOLDER" ] && continue
            
            REPORT_NAME=$(basename "$REPORT_FOLDER" .Report)
            
            echo ""
            echo "================================================"
            echo "üìä Deploying Report: $REPORT_NAME"
            echo "   Folder: $REPORT_FOLDER"
            echo "================================================"
            
            # Determine the definition folder location
            DEFINITION_FOLDER=""
            if [ -d "$REPORT_FOLDER/definition" ] && [ "$(find "$REPORT_FOLDER/definition" -type f | wc -l)" -gt 0 ]; then
              DEFINITION_FOLDER="$REPORT_FOLDER/definition"
            else
              echo "‚ö†Ô∏è  Warning: No definition folder found or it's empty"
              echo "   Looking for files in root folder instead"
              DEFINITION_FOLDER="$REPORT_FOLDER"
            fi
            
            echo "   Using definition folder: $DEFINITION_FOLDER"
            
            # Build definition payload from all files in definition folder
            PAYLOAD_PARTS="["
            FIRST_FILE=true
            FILE_COUNT=0
            
            # Process all files in the definition folder (excluding .platform and other metadata)
            while IFS= read -r FILE; do
              [ -z "$FILE" ] && continue
              
              # Skip .platform and other non-definition files
              BASENAME=$(basename "$FILE")
              if [[ "$BASENAME" == ".platform" ]] || [[ "$BASENAME" == ".pbi"* ]]; then
                continue
              fi
              
              # Calculate relative path - MUST include 'definition/' prefix for Fabric API
              if [ "$DEFINITION_FOLDER" = "$REPORT_FOLDER/definition" ]; then
                # Files are in definition subfolder, prepend 'definition/' to path
                RELATIVE_PATH="definition/${FILE#$REPORT_FOLDER/definition/}"
              else
                # Files are in root folder, use as-is
                RELATIVE_PATH="${FILE#$REPORT_FOLDER/}"
              fi
              
              # Read and encode file content
              FILE_CONTENT=$(base64 -w 0 < "$FILE")
              
              if [ "$FIRST_FILE" = false ]; then
                PAYLOAD_PARTS="$PAYLOAD_PARTS,"
              fi
              FIRST_FILE=false
              
              PAYLOAD_PARTS="$PAYLOAD_PARTS{\"path\":\"$RELATIVE_PATH\",\"payload\":\"$FILE_CONTENT\",\"payloadType\":\"InlineBase64\"}"
              FILE_COUNT=$((FILE_COUNT + 1))
              
              echo "   üìÑ Added file: $RELATIVE_PATH"
              
            done < <(find "$DEFINITION_FOLDER" -type f | sort)
            
            PAYLOAD_PARTS="$PAYLOAD_PARTS]"
            
            echo "   Total files to upload: $FILE_COUNT"
            echo ""
            echo "   üöÄ Creating report in workspace..."
            
            # Create report in workspace
            RESPONSE=$(curl -s -w "\nHTTP_STATUS:%{http_code}" -X POST \
              "${{ env.FABRIC_API_BASE_URL }}/workspaces/C5FAF867-77B6-499A-A8CD-C00C3C046218/reports" \
              -H "Authorization: Bearer ${{ env.FABRIC_TOKEN }}" \
              -H "Content-Type: application/json" \
              -d "{\"displayName\":\"$REPORT_NAME\",\"definition\":{\"parts\":$PAYLOAD_PARTS}}")
            
            HTTP_STATUS=$(echo "$RESPONSE" | grep HTTP_STATUS | cut -d: -f2)
            BODY=$(echo "$RESPONSE" | sed '/HTTP_STATUS/d')
            
            if [ "$HTTP_STATUS" -eq 200 ] || [ "$HTTP_STATUS" -eq 201 ] || [ "$HTTP_STATUS" -eq 202 ]; then
              REPORT_ID=$(echo "$BODY" | jq -r '.id // "unknown"')
              echo "   ‚úÖ Successfully deployed: $REPORT_NAME"
              echo "   üìã Report ID: $REPORT_ID"
              SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
              DEPLOYED_REPORTS="$DEPLOYED_REPORTS$REPORT_NAME, "
            else
              echo "   ‚ùå Failed to deploy: $REPORT_NAME"
              echo "   üìä Status: $HTTP_STATUS"
              echo "   üìù Response: $BODY"
              FAILED_COUNT=$((FAILED_COUNT + 1))
            fi
            
          done < /tmp/reports_to_deploy.txt
          
          DEPLOYED_REPORTS=${DEPLOYED_REPORTS%, }
          
          echo ""
          echo "=========================================="
          echo "REPORTS DEPLOYMENT SUMMARY"
          echo "=========================================="
          echo "Total found: ${{ steps.find-files.outputs.report_count }}"
          echo "‚úÖ Success: $SUCCESS_COUNT"
          echo "‚ùå Failed: $FAILED_COUNT"
          echo "=========================================="
          
          echo "deployed_reports=$DEPLOYED_REPORTS" >> $GITHUB_OUTPUT
          echo "report_success=$SUCCESS_COUNT" >> $GITHUB_OUTPUT
          echo "report_failed=$FAILED_COUNT" >> $GITHUB_OUTPUT
      
      - name: Final Deployment Status
        id: deployment
        run: |
          DATASET_SUCCESS=${{ steps.deploy-datasets.outputs.dataset_success || 0 }}
          DATASET_FAILED=${{ steps.deploy-datasets.outputs.dataset_failed || 0 }}
          REPORT_SUCCESS=${{ steps.deploy-reports.outputs.report_success || 0 }}
          REPORT_FAILED=${{ steps.deploy-reports.outputs.report_failed || 0 }}
          
          TOTAL_SUCCESS=$((DATASET_SUCCESS + REPORT_SUCCESS))
          TOTAL_FAILED=$((DATASET_FAILED + REPORT_FAILED))
          TOTAL_ITEMS=${{ steps.find-files.outputs.total_count }}
          
          echo ""
          echo "=========================================="
          echo "OVERALL DEPLOYMENT SUMMARY"
          echo "=========================================="
          echo "Environment: ${{ inputs.environment }}"
          echo "Workspace: ${{ steps.validate.outputs.workspace_name }}"
          echo "Branch: ${{ inputs.branch }}"
          echo ""
          echo "üìä Semantic Models: $DATASET_SUCCESS deployed, $DATASET_FAILED failed"
          echo "üìà Reports: $REPORT_SUCCESS deployed, $REPORT_FAILED failed"
          echo "----------------------------------------"
          echo "üéØ Total: $TOTAL_SUCCESS/$TOTAL_ITEMS succeeded"
          echo "=========================================="
          
          echo "deployed_reports=${{ steps.deploy-reports.outputs.deployed_reports }}" >> $GITHUB_OUTPUT
          echo "deployed_datasets=${{ steps.deploy-datasets.outputs.deployed_datasets }}" >> $GITHUB_OUTPUT
          
          if [ $TOTAL_FAILED -eq 0 ]; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo ""
            echo "‚úÖ‚úÖ‚úÖ ALL ITEMS DEPLOYED SUCCESSFULLY! ‚úÖ‚úÖ‚úÖ"
          elif [ $TOTAL_SUCCESS -gt 0 ]; then
            echo "status=partial" >> $GITHUB_OUTPUT
            echo ""
            echo "‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è PARTIAL DEPLOYMENT - SOME ITEMS FAILED ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è"
            exit 1
          else
            echo "status=failed" >> $GITHUB_OUTPUT
            echo ""
            echo "‚ùå‚ùå‚ùå ALL DEPLOYMENTS FAILED ‚ùå‚ùå‚ùå"
            exit 1
          fi
      
      - name: Post Deployment Summary
        if: always()
        run: |
          echo "## üöÄ Deployment Summary - ${{ inputs.environment }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Property | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| **Environment** | \`${{ inputs.environment }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| **Workspace** | ${{ steps.validate.outputs.workspace_name }} |" >> $GITHUB_STEP_SUMMARY
          echo "| **Workspace ID** | \`${{ inputs.workspace_id }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| **Branch** | \`${{ inputs.branch }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| **Status** | ${{ steps.deployment.outputs.status || 'failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### üìä Semantic Models" >> $GITHUB_STEP_SUMMARY
          echo "- **Found:** ${{ steps.find-files.outputs.dataset_count || '0' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Deployed:** ${{ steps.deploy-datasets.outputs.dataset_success || '0' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Failed:** ${{ steps.deploy-datasets.outputs.dataset_failed || '0' }}" >> $GITHUB_STEP_SUMMARY
          
          if [ -n "${{ steps.deploy-datasets.outputs.deployed_datasets }}" ]; then
            echo "- **Items:** ${{ steps.deploy-datasets.outputs.deployed_datasets }}" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### üìà Reports" >> $GITHUB_STEP_SUMMARY
          echo "- **Found:** ${{ steps.find-files.outputs.report_count || '0' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Deployed:** ${{ steps.deploy-reports.outputs.report_success || '0' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Failed:** ${{ steps.deploy-reports.outputs.report_failed || '0' }}" >> $GITHUB_STEP_SUMMARY
          
          if [ -n "${{ steps.deploy-reports.outputs.deployed_reports }}" ]; then
            echo "- **Items:** ${{ steps.deploy-reports.outputs.deployed_reports }}" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ steps.deployment.outputs.status }}" = "success" ]; then
            echo "‚úÖ **All items deployed successfully**" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ steps.deployment.outputs.status }}" = "partial" ]; then
            echo "‚ö†Ô∏è **Some items failed to deploy**" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ùå **Deployment failed**" >> $GITHUB_STEP_SUMMARY
          fi
